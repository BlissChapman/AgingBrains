{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import copy\n",
    "import cv2\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import seaborn as sns\n",
    "\n",
    "from matplotlib.offsetbox import OffsetImage, AnnotationBbox\n",
    "\n",
    "from scipy.stats import chi2\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn import manifold\n",
    "from sklearn.mixture import GaussianMixture\n",
    "from sklearn.metrics.pairwise import cosine_distances\n",
    "from sklearn.preprocessing import MinMaxScaler, StandardScaler\n",
    "\n",
    "import statsmodels.api as sm\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torch import nn, optim\n",
    "from torch.autograd import Variable, grad\n",
    "from torch.nn import functional as F\n",
    "from torchvision import datasets\n",
    "from torchvision import transforms\n",
    "from torchvision.utils import save_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# VAE Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class VAE(nn.Module):\n",
    "    \n",
    "    def __init__(self):\n",
    "        super(VAE, self).__init__()\n",
    "\n",
    "        self.dimensionality = 64\n",
    "        \n",
    "        # (Wâˆ’F+2P)/S+1\n",
    "        # After conv_1, we have a (28-2)/2 + 1 => (14x14) image with 64 channels\n",
    "        self.conv_1 = nn.Conv2d(1, self.dimensionality, \n",
    "                                kernel_size=(2, 2),\n",
    "                                stride=2)\n",
    "\n",
    "        # After conv_2, we have a (14-2)/2 + 1 => (7x7) image with 128 channels\n",
    "        self.conv_2 = nn.Conv2d(self.dimensionality, 2*self.dimensionality, \n",
    "                                kernel_size=(2, 2), \n",
    "                                stride=2)\n",
    " \n",
    "        self.fc31 = nn.Linear((self.dimensionality*2)*7*7, 20)\n",
    "        self.fc32 = nn.Linear((self.dimensionality*2)*7*7, 20)\n",
    "        \n",
    "        self.fc4 = nn.Linear(20, (2*self.dimensionality)*7*7)\n",
    "        \n",
    "        # S*(N-1) + F - 2P\n",
    "        # After deconv_5, we have a 2*(7-1) + 2 => 14x14 image with 64 channels\n",
    "        self.deconv_5 = nn.ConvTranspose2d(2*self.dimensionality, self.dimensionality,\n",
    "                                           kernel_size=(2, 2),\n",
    "                                           stride=2)\n",
    "        # After deconv_6, we have a 2*(14-1) + 2 => 28x28 image with 1 channel\n",
    "        self.deconv_6 = nn.ConvTranspose2d(self.dimensionality, 1, \n",
    "                                           kernel_size=(2, 2),\n",
    "                                           stride=2)\n",
    "                \n",
    "        self.optimizer = optim.Adam(self.parameters(), lr=1e-3)\n",
    "\n",
    "    def encode(self, x):\n",
    "        x = x.view(-1, 1, 28, 28)\n",
    "        x = F.relu(self.conv_1(x))\n",
    "        x = F.relu(self.conv_2(x))\n",
    "        x = x.view(-1, x.shape[1]*x.shape[2]*x.shape[3])\n",
    "        return self.fc31(x), self.fc32(x)\n",
    "\n",
    "    def _reparameterize(self, mu, logvar):\n",
    "        std = torch.exp(0.5*logvar)\n",
    "        eps = Variable(torch.randn(std.shape))\n",
    "        return eps.mul(std).add_(mu)\n",
    "\n",
    "    def decode(self, z):\n",
    "        h = F.relu(self.fc4(z))\n",
    "        h = h.view(-1, 2*self.dimensionality, 7, 7)\n",
    "        h = F.relu(self.deconv_5(h))\n",
    "        h = torch.sigmoid(self.deconv_6(h))\n",
    "        return h.view(-1, 28, 28)\n",
    "\n",
    "    def forward(self, x):\n",
    "        mu, logvar = self.encode(x)\n",
    "        z = self._reparameterize(mu, logvar)\n",
    "        return self.decode(z), mu, logvar\n",
    "    \n",
    "    def loss(self, x, reconstructed_x, mu, log_var):\n",
    "\n",
    "        # Maximize P(x)\n",
    "        # => Since P(x,z) = P(z|x)P(x), P(x) = P(x,z) / P(z|x)\n",
    "        # => log P(x) = log P(x,z) - log P(z|x)\n",
    "        # => log P(x) = log P(x,z) - log Q(z) - log P(z|x) + log Q(z)\n",
    "        # => log P(x) = log [P(x,z)/Q(z)] - log[P(z|x)/Q(z)]\n",
    "        # => E_Q(z)[log(P(x))] = E_Q(z)[log [P(x,z)/Q(z)]] - E_Q(z)[log[P(z|x)/Q(z)]]\n",
    "        # => log(P(x)) = E_Q(z)[log [P(x,z)/Q(z)]] - KL(P(z|x) || Q(z))\n",
    "        # => log(P(x)) >= E_Q(z)[log [P(x,z)/Q(z)]]\n",
    "        # => log(P(x)) >= E_Q(z)[log P(x,z)] - E_Q(z)[log Q(z)]\n",
    "        # => log(P(x)) >= E_Q(z)[log P(x|z)] + E_Q(z)[log P(z)] - E_Q(z)[log Q(z)]\n",
    "        # => log(P(x)) >= E_Q(z)[log P(x|z)] - KL(P(z) || Q(z))\n",
    "        # So...\n",
    "        # Minimizing - log(P(x)) can be accomplished by minimizing loss = KL(P(z) || Q(z)) - E_Q(z)[log P(x|z)]]\n",
    "        \n",
    "        # KL(P(z) || Q(z))\n",
    "        # When P(z) and Q(z) are restricted to be gaussians with Q(z) ~ N(0, 1):\n",
    "        # KL(P(z) || Q(z)) = -0.5*ln(sigma_i) + 0.5*sigma_i^2 + 0.5*mu_i^2 - 0.5\n",
    "        # => KL(P(z) || Q(z)) = 0.5 * sum_i [sigma_i^2 + mu_i^2 - ln(sigma_i) - 1]\n",
    "        kld = 0.5 * torch.sum(log_var.exp() + mu.pow(2) - log_var - 1.)\n",
    "        \n",
    "        # - E[log P(x|z)]        \n",
    "        reconstruction = F.binary_cross_entropy(reconstructed_x.view(-1, 784), x.view(-1, 784))\n",
    "\n",
    "        return reconstruction + kld\n",
    "    \n",
    "    def train(self, train_loader):\n",
    "        sum_train_loss = 0\n",
    "        sum_likelihood = 0\n",
    "        \n",
    "        for batch_idx, (data_batch, _) in enumerate(train_loader):\n",
    "            data_batch = Variable(data_batch)\n",
    "            \n",
    "            self.zero_grad()\n",
    "            reconstructed_batch, mu, log_var = self(data_batch)\n",
    "            loss = self.loss(data_batch, reconstructed_batch, mu, log_var)\n",
    "            loss.backward()\n",
    "            sum_train_loss += loss.item()\n",
    "            sum_likelihood += 0 # self.likelihood(data_batch, reconstructed_batch, mu, log_var)\n",
    "            self.optimizer.step()\n",
    "            \n",
    "        return sum_train_loss, sum_likelihood"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### VAE Train Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_vae(model, model_name, train_loader, num_epochs=1000, log_interval=5):\n",
    "    for epoch in range(1, num_epochs+1):\n",
    "        sum_train_loss, sum_likelihood = model.train(train_loader)\n",
    "        print(\"EPOCH {0}\".format(epoch))\n",
    "        print(\"    SUM TRAIN LOSS : {0}\".format(sum_train_loss))\n",
    "        print(\"    MEAN LIKELIHOOD: {0}\".format(sum_likelihood/len(train_loader)))\n",
    "        \n",
    "        if epoch % log_interval == 0:\n",
    "            sample = Variable(torch.randn(64, 20))\n",
    "            sample = model.decode(sample).data\n",
    "            save_image(sample.view(64, 1, 28, 28), 'OUTPUT/reconstructed_samples/sample_{0}_{1}.png'.format(model_name, epoch))\n",
    "            torch.save(model.state_dict(), 'OUTPUT/vae_models/{0}_epoch={1}.pt'.format(model_name, epoch))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE on Full MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hyperparameters\n",
    "BATCH_SIZE = 128"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load train and test data\n",
    "mnist_train_dataset = datasets.MNIST('DATA/', train=True, download=True, transform=transforms.ToTensor())\n",
    "mnist_test_dataset = datasets.MNIST('DATA/', train=False, download=True, transform=transforms.ToTensor())\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(mnist_train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = torch.utils.data.DataLoader(mnist_test_dataset, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "full_mnist_model = VAE()\n",
    "# full_mnist_model.load_state_dict(torch.load('OUTPUT/vae_models/model.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR:root:No traceback has been produced, nothing to debug.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "EPOCH 1\n",
      "    SUM TRAIN LOSS : 300.28398713469505\n",
      "    MEAN LIKELIHOOD: 0.0\n",
      "EPOCH 2\n",
      "    SUM TRAIN LOSS : 124.61038218438625\n",
      "    MEAN LIKELIHOOD: 0.0\n",
      "EPOCH 3\n",
      "    SUM TRAIN LOSS : 124.06747955083847\n",
      "    MEAN LIKELIHOOD: 0.0\n"
     ]
    }
   ],
   "source": [
    "# Train model\n",
    "train_vae(full_mnist_model, 'full_mnist_model', train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train VAE on Subset MNIST Dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def build_mnist_dataset_with_only_label_from_dataset(d, label, test=False):\n",
    "    nd = copy.deepcopy(d)\n",
    "    idxs_with_label = []\n",
    "    \n",
    "    for i in range(0, len(d)):  \n",
    "        if d[i][1] == label:\n",
    "            idxs_with_label.append(i)\n",
    "    \n",
    "    if test:\n",
    "        nd.test_data = nd.test_data[idxs_with_label]\n",
    "        nd.test_labels = nd.test_labels[idxs_with_label]\n",
    "    else:\n",
    "        nd.train_data = nd.train_data[idxs_with_label]\n",
    "        nd.train_labels = nd.train_labels[idxs_with_label]\n",
    "            \n",
    "    return nd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset_8 = build_mnist_dataset_with_only_label_from_dataset(mnist_train_dataset, 8)\n",
    "mnist_test_dataset_8 = build_mnist_dataset_with_only_label_from_dataset(mnist_test_dataset, 8, test=True)\n",
    "mnist_test_dataset_6 = build_mnist_dataset_with_only_label_from_dataset(mnist_test_dataset, 6, test=True)\n",
    "mnist_test_dataset_2 = build_mnist_dataset_with_only_label_from_dataset(mnist_test_dataset, 2, test=True)\n",
    "mnist_test_dataset_1 = build_mnist_dataset_with_only_label_from_dataset(mnist_test_dataset, 1, test=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build train loader for dataset of 8's.\n",
    "BATCH_SIZE = 128\n",
    "mnist_8_train_loader = torch.utils.data.DataLoader(mnist_train_dataset_8, batch_size=BATCH_SIZE, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Construct model\n",
    "mnist_8_model = VAE()\n",
    "mnist_8_model.load_state_dict(torch.load('OUTPUT/vae_models/mnist_8_model_epoch=230.pt'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train VAE on dataset of only 8's.\n",
    "#train_vae(mnist_8_model, 'mnist_8_model', mnist_8_train_loader)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 1: Permute Latent Space Along Principal Components"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encode training set into latent space\n",
    "z_batches = []\n",
    "data_batches = []\n",
    "\n",
    "for batch_idx, (data_batch, _) in enumerate(train_loader):\n",
    "    data_batches.append(data_batch)\n",
    "    data_batch = Variable(data_batch)\n",
    "    mu, logvar = full_mnist_model.encode(data_batch)\n",
    "    z = full_mnist_model._reparameterize(mu, logvar)\n",
    "    z_batches.append(z.data.numpy())\n",
    "     \n",
    "z = np.concatenate(z_batches, axis=0)\n",
    "data = np.concatenate(data_batches, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compute mean of latent space\n",
    "z_mu = np.mean(z, axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Apply PCA to latent feature vectors\n",
    "pca = PCA(n_components=10)\n",
    "pca.fit(z)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(pca.components_.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "C = 3\n",
    "i = 0\n",
    "for principal_component in pca.components_:\n",
    "    i += 1\n",
    "    z_permuted = z_mu + C*principal_component\n",
    "    z_permuted = Variable(torch.from_numpy(z_permuted))\n",
    "    permuted_img = full_mnist_model.decode(z_permuted).data\n",
    "    save_image(permuted_img.view(1, 1, 28, 28), 'OUTPUT/permuted_principal_component_samples/sample_' + str(i) + '.png')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 2: Cluster Latent Encodings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kmeans = KMeans(n_clusters=10, random_state=0).fit(z)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Decode cluster center.\n",
    "2. Find image in training set with closest latent space encoding to cluster_center."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "i = 0\n",
    "for cluster_center in kmeans.cluster_centers_:\n",
    "    i += 1\n",
    "    \n",
    "    # Decode cluster center\n",
    "    cluster_center_var = Variable(torch.from_numpy(cluster_center))\n",
    "    decoded_cluster_center = full_mnist_model.decode(cluster_center_var)\n",
    "    save_image(decoded_cluster_center.data.view(1, 1, 28, 28), 'OUTPUT/train_set_decoded_latent_space_cluster_centers/decoded_cluster_center_' + str(i) + '.png') \n",
    "    \n",
    "    # Find image in training set with closest latent space encoding to cluster_center\n",
    "    closest_distance = float(\"inf\")\n",
    "    closest_distance_data = None\n",
    "    for (z_i, data_i) in zip(z, data):\n",
    "        distance_i = cosine_distances([z_i], [cluster_center])\n",
    "        if (distance_i < closest_distance):\n",
    "            closest_distance = distance_i\n",
    "            closest_distance_data = torch.from_numpy(data_i)\n",
    "        \n",
    "    save_image(closest_distance_data.view(1, 1, 28, 28), 'OUTPUT/train_set_imgs_closest_to_latent_space_cluster_centers/cluster_' + str(i) + '_representative.png') "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 3: Contrived Outlier Problem (MNIST)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot examples of test dataset digits."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "example_test_8 = mnist_test_dataset_8[0][0]\n",
    "example_test_6 = mnist_test_dataset_6[1][0]\n",
    "example_test_2 = mnist_test_dataset_2[1][0]\n",
    "example_test_1 = mnist_test_dataset_1[1][0]\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(example_test_8.view(28, 28))\n",
    "axes[0, 1].imshow(example_test_6.view(28, 28))\n",
    "axes[1, 0].imshow(example_test_2.view(28, 28))\n",
    "axes[1, 1].imshow(example_test_1.view(28, 28))\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3.1: Likelihood Statistic Approach"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Reconstruct each of the example digits using the VAE trained on only 8s."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reconstructed_example_test_8, _, _ = mnist_8_model(Variable(example_test_8))\n",
    "reconstructed_example_test_6, _, _ = mnist_8_model(Variable(example_test_6))\n",
    "reconstructed_example_test_2, _, _ = mnist_8_model(Variable(example_test_2))\n",
    "reconstructed_example_test_1, _, _ = mnist_8_model(Variable(example_test_1))\n",
    "\n",
    "likelihood_statistic_example_test_8 = mnist_8_model.likelihood_statistic(example_test_8).data.item()\n",
    "likelihood_statistic_example_test_6 = mnist_8_model.likelihood_statistic(example_test_6).data.item()\n",
    "likelihood_statistic_example_test_2 = mnist_8_model.likelihood_statistic(example_test_2).data.item()\n",
    "likelihood_statistic_example_test_1 = mnist_8_model.likelihood_statistic(example_test_1).data.item()\n",
    "\n",
    "fig, axes = plt.subplots(2, 2)\n",
    "axes[0, 0].imshow(reconstructed_example_test_8.view(28, 28).data)\n",
    "axes[0, 1].imshow(reconstructed_example_test_6.view(28, 28).data)\n",
    "axes[1, 0].imshow(reconstructed_example_test_2.view(28, 28).data)\n",
    "axes[1, 1].imshow(reconstructed_example_test_1.view(28, 28).data)\n",
    "\n",
    "axes[0, 0].set_title(\"LS: {0:.4f}\".format(likelihood_statistic_example_test_8))\n",
    "axes[0, 1].set_title(\"LS: {0:.4f}\".format(likelihood_statistic_example_test_6))\n",
    "axes[1, 0].set_title(\"LS: {0:.4f}\".format(likelihood_statistic_example_test_2))\n",
    "axes[1, 1].set_title(\"LS: {0:.4f}\".format(likelihood_statistic_example_test_1))\n",
    "plt.subplots_adjust(hspace=0.5)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build null distribution of likelihood statistics from training set values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset_8_likelihood_statistics = mnist_8_model.likelihood_statistics_for_dataset(mnist_train_dataset_8)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Build distributions of likelihood statistics from test set values."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_test_dataset_8_likelihood_statistics = mnist_8_model.likelihood_statistics_for_dataset(mnist_test_dataset_8)\n",
    "mnist_test_dataset_6_likelihood_statistics = mnist_8_model.likelihood_statistics_for_dataset(mnist_test_dataset_6)\n",
    "mnist_test_dataset_2_likelihood_statistics = mnist_8_model.likelihood_statistics_for_dataset(mnist_test_dataset_2)\n",
    "mnist_test_dataset_1_likelihood_statistics = mnist_8_model.likelihood_statistics_for_dataset(mnist_test_dataset_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot null and test distributions of likelihood statistics together!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.hist(mnist_train_dataset_8_likelihood_statistics, density=True, color=(0.5, 0.5, 0.5, 0.3))\n",
    "plt.hist(mnist_test_dataset_8_likelihood_statistics, density=True, color=(1., 0, 0, 0.3))\n",
    "plt.hist(mnist_test_dataset_6_likelihood_statistics, density=True, color=(0, 1., 0, 0.3))\n",
    "plt.hist(mnist_test_dataset_2_likelihood_statistics, density=True, color=(0.1, 1., 1., 0.3))\n",
    "plt.hist(mnist_test_dataset_1_likelihood_statistics, density=True, color=(0, 0, 1., 0.3))\n",
    "plt.legend(['Training Set of 8s (Null)', 'Test Set of 8s', 'Test Set of 6s', 'Test Set of 2s', 'Test Set of 1s'])\n",
    "plt.title(\"Distributions of Likelihood Statistics\")\n",
    "plt.xlabel(\"Likelihood Statistic Values\")\n",
    "plt.ylabel(\"Likelihood Statistic Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Experiment 3.1.1: Classify Outliers on Count of Null Statistics Below Test Pt Likelihood Statistic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def classify_outliers_report(null_pts, test_pts, alpha=0.05):\n",
    "    \n",
    "    num_outliers = 0\n",
    "    num_non_outliers = 0\n",
    "    N = len(null_pts)\n",
    "    \n",
    "    for test_pt in test_pts:\n",
    "        p_value_left_tail = sum(null_pt < test_pt for null_pt in null_pts) / N\n",
    "            \n",
    "        if p_value_left_tail < alpha:\n",
    "            num_outliers += 1\n",
    "        else:\n",
    "            num_non_outliers += 1\n",
    "            \n",
    "    print(\"%     OUTLIERS: {0}\".format(100 * num_outliers / len(test_pts)))\n",
    "    print(\"% NON OUTLIERS: {0}\".format(100 * num_non_outliers / len(test_pts)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test inlier classification performance on training 8s"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_outliers_report(mnist_train_dataset_8_likelihood_statistics, mnist_train_dataset_8_likelihood_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test inlier classification performance on test 8s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_outliers_report(mnist_train_dataset_8_likelihood_statistics, mnist_test_dataset_8_likelihood_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Test outlier classification performance on 6s, 2s, 1s:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_outliers_report(mnist_train_dataset_8_likelihood_statistics, mnist_test_dataset_6_likelihood_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_outliers_report(mnist_train_dataset_8_likelihood_statistics, mnist_test_dataset_2_likelihood_statistics)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classify_outliers_report(mnist_train_dataset_8_likelihood_statistics, mnist_test_dataset_1_likelihood_statistics)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Experiment 3.2: Distance From Mean Statistic Approach"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset_8_images = []\n",
    "for elem in mnist_train_dataset_8:\n",
    "    mnist_train_dataset_8_images.append(elem[0].view(28, 28).numpy())\n",
    "\n",
    "mnist_train_dataset_8_images_mean = np.mean(mnist_train_dataset_8_images, axis=0)\n",
    "plt.imshow(mnist_train_dataset_8_images_mean)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEA: Distance in image space could be defined as distance in activations of a \n",
    "#  classifier trained on a similar problem.\n",
    "\n",
    "def distance_between_images(img1, img2):\n",
    "    return np.sum(pow(img1.flatten() - img2.flatten(), 2))\n",
    "\n",
    "def compute_distances_from_image(dataset, image):\n",
    "    distances = []\n",
    "    for elem in dataset:\n",
    "        distance = distance_between_images(elem[0].numpy(), image)\n",
    "        distances.append(distance)\n",
    "    return distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train_dataset_8_distance_statistics = compute_distances_from_image(mnist_train_dataset_8, mnist_train_dataset_8_images_mean)\n",
    "mnist_test_dataset_8_distance_statistics = compute_distances_from_image(mnist_test_dataset_8, mnist_train_dataset_8_images_mean)\n",
    "mnist_test_dataset_6_distance_statistics = compute_distances_from_image(mnist_test_dataset_6, mnist_train_dataset_8_images_mean)\n",
    "mnist_test_dataset_2_distance_statistics = compute_distances_from_image(mnist_test_dataset_2, mnist_train_dataset_8_images_mean)\n",
    "mnist_test_dataset_1_distance_statistics = compute_distances_from_image(mnist_test_dataset_1, mnist_train_dataset_8_images_mean)\n",
    "\n",
    "plt.hist(mnist_train_dataset_8_distance_statistics, density=True, color=(0.5, 0.5, 0.5, 0.3))\n",
    "plt.hist(mnist_test_dataset_8_distance_statistics, density=True, color=(1., 0, 0, 0.3))\n",
    "plt.hist(mnist_test_dataset_6_distance_statistics, density=True, color=(0, 1., 0, 0.3))\n",
    "plt.hist(mnist_test_dataset_2_distance_statistics, density=True, color=(0.1, 1., 1., 0.3))\n",
    "plt.hist(mnist_test_dataset_1_distance_statistics, density=True, color=(0, 0, 1., 0.3))\n",
    "plt.legend(['Training Set of 8s (Null)', 'Test Set of 8s', 'Test Set of 6s', 'Test Set of 2s', 'Test Set of 1s'])\n",
    "plt.title(\"Distributions of Distances to Mean\")\n",
    "plt.xlabel(\"(Distance to Mean) Statistic Values\")\n",
    "plt.ylabel(\"Statistic Density\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 4: Move Through Image Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def closest_image_in_dataset_to_image(dataset, query_img):\n",
    "\n",
    "    closest_elem = None\n",
    "    closest_elem_distance = float('inf')\n",
    "    \n",
    "    for elem in dataset:\n",
    "        elem_distance = distance_between_images(elem[0].numpy(), query_img.numpy())\n",
    "        if elem_distance < closest_elem_distance:\n",
    "            closest_elem = elem[0]\n",
    "            closest_elem_distance = elem_distance\n",
    "    \n",
    "    return closest_elem.view(28, 28).numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "closest_training_set_point_to_example_test_6 = closest_image_in_dataset_to_image(mnist_train_dataset_8, example_test_6)\n",
    "plt.imshow(closest_training_set_point_to_example_test_6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_training_set_point_to_example_test_1 = closest_image_in_dataset_to_image(mnist_train_dataset_8, example_test_1)\n",
    "plt.imshow(closest_training_set_point_to_example_test_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interpolate pixel values individually between example_test_6 and closest_training_set_point_to_example_test_6\n",
    "diff_6 = (closest_training_set_point_to_example_test_6 - example_test_6.numpy()).reshape(28,28)\n",
    "diff_1 = (closest_training_set_point_to_example_test_1 - example_test_1.numpy()).reshape(28,28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_interpolation_steps = 5\n",
    "\n",
    "f, axs = plt.subplots(1, 6)\n",
    "for i in range(0, num_interpolation_steps+1):\n",
    "    interpolation_i = example_test_6.view(28, 28).numpy() + (i/num_interpolation_steps)*diff_6\n",
    "    axs[i].imshow(interpolation_i)\n",
    "plt.show(f)\n",
    "    \n",
    "f2, axs2 = plt.subplots(1, 6)\n",
    "for i in range(0, num_interpolation_steps+1):\n",
    "    interpolation_i = example_test_1.view(28, 28).numpy() + (i/num_interpolation_steps)*diff_1\n",
    "    axs2[i].imshow(interpolation_i)\n",
    "plt.show(f2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 5: Move Through Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def distance_between_images_in_latent_space(img1, img2):\n",
    "    \n",
    "    img1 = Variable(img1)\n",
    "    img2 = Variable(img2)\n",
    "    \n",
    "    mu1, logvar1 = mnist_8_model.encode(img1)\n",
    "    mu2, logvar2 = mnist_8_model.encode(img2)\n",
    "    \n",
    "    # KL Divergence between univariate gaussians\n",
    "    return torch.sum(logvar2 - logvar1 + (logvar1.exp() + pow(mu1 - mu2, 2))/(2*logvar2.exp()) - 0.5).item()\n",
    "\n",
    "def closest_image_in_dataset_to_image(dataset, query_img):\n",
    "\n",
    "    closest_elem = None\n",
    "    closest_elem_distance = float('inf')\n",
    "    \n",
    "    for elem in dataset:\n",
    "        elem_distance = distance_between_images_in_latent_space(elem[0], query_img)\n",
    "        if elem_distance < closest_elem_distance:\n",
    "            closest_elem = elem[0]\n",
    "            closest_elem_distance = elem_distance\n",
    "    \n",
    "    return closest_elem.view(28, 28)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_training_set_point_in_latent_space_to_example_test_6 = closest_image_in_dataset_to_image(mnist_train_dataset_8, example_test_6)\n",
    "plt.imshow(closest_training_set_point_in_latent_space_to_example_test_6)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_training_set_point_in_latent_space_to_example_test_2 = closest_image_in_dataset_to_image(mnist_train_dataset_8, example_test_2)\n",
    "plt.imshow(closest_training_set_point_in_latent_space_to_example_test_2)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "closest_training_set_point_in_latent_space_to_example_test_1 = closest_image_in_dataset_to_image(mnist_train_dataset_8, example_test_1)\n",
    "plt.imshow(closest_training_set_point_in_latent_space_to_example_test_1)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_samples_along_path_between_images(model, img1, img2, num_samples=10, parameter_space=True):\n",
    "    \n",
    "    mu1, varlog1 = model.encode(Variable(img1))\n",
    "    mu2, varlog2 = model.encode(Variable(img2))\n",
    "    \n",
    "    mu_diff = mu2 - mu1\n",
    "    varlog_diff = varlog2 - varlog1\n",
    "    \n",
    "    f, axs = plt.subplots(1, num_samples+1, figsize=(15,5))\n",
    "    \n",
    "    for i in range(0, num_samples+1):\n",
    "        interpolation_factor = (i/num_samples)\n",
    "        if parameter_space:\n",
    "            z_i = model._reparameterize(mu1 + interpolation_factor*mu_diff, varlog1 + interpolation_factor*varlog_diff)\n",
    "        else:\n",
    "            z_i = Variable((mu1 + interpolation_factor*mu_diff).data)\n",
    "        sample_i = model.decode(z_i).view(28, 28).data.numpy()\n",
    "        \n",
    "        axs[i].get_yaxis().set_visible(False)\n",
    "        axs[i].get_xaxis().set_visible(False)\n",
    "        axs[i].imshow(sample_i)\n",
    "\n",
    "    return f"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Parameter Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_6, closest_training_set_point_in_latent_space_to_example_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_1, closest_training_set_point_in_latent_space_to_example_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_2, closest_training_set_point_in_latent_space_to_example_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_2, example_test_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Latent Space"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_6, closest_training_set_point_in_latent_space_to_example_test_6, parameter_space=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_1, closest_training_set_point_in_latent_space_to_example_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_2, closest_training_set_point_in_latent_space_to_example_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_samples_along_path_between_images(mnist_8_model, example_test_2, example_test_6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 6: Latent Space Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def imscatter(x, y, ax, imageData, zoom):\n",
    "    images = []\n",
    "    for i in range(len(x)):\n",
    "        x0, y0 = x[i], y[i]\n",
    "        \n",
    "        # Convert to image\n",
    "        img = imageData[i]*255.\n",
    "        img = img.astype(np.uint8).reshape([28, 28])\n",
    "        img = cv2.cvtColor(img,cv2.COLOR_GRAY2RGB)\n",
    "        \n",
    "        # Note: OpenCV uses BGR and plt uses RGB\n",
    "        image = OffsetImage(img, zoom=zoom)\n",
    "        ab = AnnotationBbox(image, (x0, y0), xycoords='data', frameon=False)\n",
    "        images.append(ax.add_artist(ab))\n",
    "    \n",
    "    ax.update_datalim(np.column_stack([x, y]))\n",
    "    ax.autoscale()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Show dataset images with T-sne projection of latent space encoding\n",
    "def plotTSNEProjectionOfLatentSpace(X, model):\n",
    "    \n",
    "    # Compute latent space representation\n",
    "    mu, logvar = model.encode(Variable(X))\n",
    "    Z = model._reparameterize(mu, logvar).data.numpy()\n",
    "\n",
    "    # Compute t-SNE embedding of latent space\n",
    "    tsne = manifold.TSNE(n_components=2, init='pca', random_state=0)\n",
    "    Z_tsne = tsne.fit_transform(Z)\n",
    "\n",
    "    # Plot images according to t-sne embedding\n",
    "    fig, ax = plt.subplots(figsize=(30,30))\n",
    "    imscatter(Z_tsne[:, 0], Z_tsne[:, 1], imageData=X.numpy(), ax=ax, zoom=0.6)\n",
    "    return fig"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick first 1000 elements of train dataset\n",
    "X = []\n",
    "for i in range(0,1000):\n",
    "    X.append(mnist_train_dataset[i][0])\n",
    "X = torch.stack(X)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTSNEProjectionOfLatentSpace(X, mnist_8_model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plotTSNEProjectionOfLatentSpace(X, full_mnist_model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Experiment 7: Saliency Maps"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Likelihood Statistic Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def saliency_map(model, x):\n",
    "    \n",
    "    # Wrap the input tensor in a Variable\n",
    "    x = Variable(x, requires_grad=True)\n",
    "\n",
    "    # Forward pass\n",
    "    reconstructed_x, mu, log_var = model(x)\n",
    "\n",
    "    # Recall:\n",
    "    # => log(P(x)) >= E_Q(z)[log P(x|z)] - KL(P(z) || Q(z))\n",
    "        \n",
    "    # E[log P(X|z)]\n",
    "    reconstruction = - F.binary_cross_entropy(x.view(-1, 784), reconstructed_x.view(-1, 784).detach())\n",
    "        \n",
    "    # - KL(P(z) || Q(z))\n",
    "    kld = -0.5 * torch.sum(log_var.exp() + mu.pow(2) - log_var - 1.)\n",
    "\n",
    "    # E_Q(z)[log P(x|z)] - B*KL(P(z) || Q(z))\n",
    "    beta = 0.01\n",
    "    likelihood_statistic = reconstruction + beta*kld\n",
    "    \n",
    "    # Backward pass\n",
    "    likelihood_statistic.backward(gradient=torch.ones_like(likelihood_statistic))    \n",
    "    \n",
    "    # Saliency map from gradients of input\n",
    "    saliency = x.grad.data.numpy().reshape(28, 28)\n",
    "    \n",
    "    return saliency\n",
    "\n",
    "def visualize_saliency_map(model, x):\n",
    "    saliency = saliency_map(model, x)\n",
    "\n",
    "    sns.heatmap(saliency, cmap='RdBu_r', alpha=1.0)\n",
    "    plt.title(\"Saliency Map\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_saliency_map(full_mnist_model, example_test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_saliency_map(full_mnist_model, example_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_saliency_map(full_mnist_model, example_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_saliency_map(full_mnist_model, example_test_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Encoder Mean and Var Saliency Map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def _encoder_saliency_map(model, x, target):\n",
    "    \n",
    "    # Wrap the input tensor in a Variable\n",
    "    x = Variable(x, requires_grad=True)\n",
    "\n",
    "    # Forward pass\n",
    "    output = model.encode(x)[target]\n",
    "    \n",
    "    # Backward pass\n",
    "    output.backward(gradient=torch.ones_like(output))\n",
    "    \n",
    "    # Saliency map from gradients of input\n",
    "    saliency = x.grad.data.numpy().reshape(28, 28)\n",
    "    \n",
    "    return saliency\n",
    "    \n",
    "def encoder_mean_saliency_map(model, x):\n",
    "    return _encoder_saliency_map(model, x, 0)\n",
    "\n",
    "def encoder_var_saliency_map(model, x):\n",
    "    return _encoder_saliency_map(model, x, 1)\n",
    "\n",
    "def visualize_encoder_saliency_maps(model, x):\n",
    "    mean_saliency = encoder_mean_saliency_map(model, x)\n",
    "    var_saliency = encoder_var_saliency_map(model, x)\n",
    "\n",
    "    sns.heatmap(mean_saliency, cmap='RdBu_r', alpha=0.8)\n",
    "    plt.title(\"Encoder Mean Parameter Saliency Map\")\n",
    "    plt.show()\n",
    "    \n",
    "    sns.heatmap(var_saliency, cmap='RdBu_r', alpha=0.8)\n",
    "    plt.title(\"Encoder Var Parameter Saliency Map\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_encoder_saliency_maps(full_mnist_model, example_test_8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_encoder_saliency_maps(full_mnist_model, example_test_6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_encoder_saliency_maps(full_mnist_model, example_test_2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_encoder_saliency_maps(full_mnist_model, example_test_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
